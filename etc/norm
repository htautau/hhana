#!/usr/bin/env python

"""
This performs the so-called "track fit" to determine the QCD and Z normalization
in each of the categories. These normalizations are cached in cache/norms.cache
and later used by the rest of the analysis framework.

For a list of all options this script accepts please see::

    ./norm --help
"""

from mva.cmd import fit_parser

parser = fit_parser()
args = parser.parse_args()

import sys

from rootpy.io import root_open
from rootpy.plotting import Hist2D, Hist
from rootpy.tree import Cut
from rootpy.stats import histfactory, fit

from mva import samples
from mva.massregions import MassRegions
from mva.norm import cache, log
from mva.plotting import draw_samples
from mva.categories import CATEGORIES
from mva.regions import P1P3_RECOUNTED
from mva import MMC_MASS

from matplotlib.ticker import FuncFormatter

import ROOT
from ROOT import RooMinimizer
ROOT.gSystem.Load('libTrackFit.so')


# fit the 2D recounted number of track distribution
expr = 'tau1_numTrack_recounted:tau2_numTrack_recounted'
# define the 2D boundaries and number of bins
min_edge, max_edge = .5, 4.5
bins = int(max_edge - min_edge)
integer = True
xaxis_label = "Recounted Number of Tracks"

# define the histogram template
hist_template = Hist2D(bins, min_edge, max_edge,
                       bins, min_edge, max_edge, type='D')

# temporary SS-OSff from Daniele
"""
qcd_syst = hist_template.Clone()
qcd_syst[0,0] = 1.08208
qcd_syst[0,1] = 0.975144
qcd_syst[0,2] = 0.990815
qcd_syst[0,3] = 0.90673
qcd_syst[1,0] = 0.969593
qcd_syst[1,1] = 1.04061
qcd_syst[1,2] = 0.918478
qcd_syst[1,3] = 0.921596
qcd_syst[2,0] = 1.0181
qcd_syst[2,1] = 0.944523
qcd_syst[2,2] = 0.840268
qcd_syst[2,3] = 1.08005
qcd_syst[3,0] = 0.942919
qcd_syst[3,1] = 0.85719
qcd_syst[3,2] = 0.977043
qcd_syst[3,3] = 0.92383
"""

def xtick_track_func(x, pos):
    # used by matplotlib to label the x axis with the (#track1, #track2) tuples
    ntrack1 = int((x - 1) / bins) + 1
    ntrack2 = (x - 1) % bins + 1
    return "(%d,%d)" % (ntrack1, ntrack2)

xtick_formatter = FuncFormatter(xtick_track_func)
xtick_rotation = 90
param = 'TRACK'

#control_region = Cut('%s < 100' % MMC_MASS)
#mass_regions = MassRegions(low_cutoff=60, low=100, high=180,
#                           high_sideband_in_control=False)
#control_region = mass_regions.control_region
control_region = None

fit_region = 'SS'
fit_region_alias = 'SS_TRK'
target_region = 'nOS'
virtual_region = 'SS_TRK'
model_region = 'OS'

before_name = "bkg_before_%sfit" % param
after_name = "bkg_after_%sfit" % param

year = 2012
systematics = False

ztt = samples.MC_Ztautau(
    year=year,
    systematics=False)

ztt_embedded = samples.Embedded_Ztautau(
    year=year,
    systematics=False)

others = samples.Others(
    year=year,
    systematics=systematics)

data = samples.Data(year=year)

qcd = samples.QCD(
    data=data,
    mc=[ztt, others],
    shape_region=fit_region)
qcd._label = 'QCD Multi-jet'
qcd._label_root = qcd._label

higgs = samples.Higgs(
    year=year,
    mass=125,
    systematics=systematics,
    linecolor='red')


# loop over category definitions
for cat_def in args.categories:
    # loop over the categories
    for category in CATEGORIES[cat_def]:

        print
        print "=" * 40
        print category.name
        print "=" * 40
        print

        log.info(data.cuts(category, model_region))

        qcd.shape_region = fit_region
        ztt.scale = 1.
        ztt.scale_error = 0.
        qcd.scale = 1.
        qcd.scale_error = 0.
        scale_init = 1.

        # Determine scale factor to get from 1p3p embedded Z to 1p3p ALPGEN Z
        sf_embed_13 = ztt.events(category, 'OS_TRK')[1].value / ztt_embedded.events(category, 'OS_TRK')[1].value
        sf_embed = ztt.events(category, 'OS')[1].value / ztt_embedded.events(category, 'OS')[1].value

        """
        # Initialize Z scale to (data - QCD - others) / Z
        # so we get good convergence for ALPGEN or embedded Z
        data_events = data.events(category, model_region, cuts=control_region)
        qcd_events = qcd.events(category, model_region, cuts=control_region)
        oth_events = others.events(category, model_region, cuts=control_region)
        z_events = ztt.events(category, model_region, cuts=control_region)
        scale_init = (data_events - qcd_events - oth_events) / float(z_events)
        ztt.scale = scale_init
        log.info("initial Z scale before fit: %f" % scale_init)
        """

        if args.plot:
            # Draw the distribution before the fit
            draw_samples(hist_template, expr,
                model=[qcd, others, ztt],
                data=data,
                category=category,
                region=model_region,
                cuts=control_region,
                name=xaxis_label,
                output_name=before_name,
                show_ratio=True,
                systematics=None,
                ravel=hist_template.GetDimension() > 1,
                integer=integer,
                xtick_formatter=xtick_formatter,
                xtick_rotation=xtick_rotation,
                output_formats=['eps', 'png'])

        data_hist = hist_template.Clone()
        data.draw_into(data_hist, expr, category, model_region,
                cuts=control_region, systematics=False)

        tau_hist = hist_template.Clone()
        ztt.draw_into(tau_hist, expr, category, model_region,
                cuts=control_region, systematics=False)

        others_hist = hist_template.Clone()
        others.draw_into(others_hist, expr, category, model_region,
                cuts=control_region, systematics=False)

        qcd_data_hist = hist_template.Clone()
        data.draw_into(qcd_data_hist, expr, category, fit_region,
                cuts=control_region, systematics=False)

        qcd_tau_hist = hist_template.Clone()
        ztt.draw_into(qcd_tau_hist, expr, category, fit_region,
                cuts=control_region, systematics=False)

        qcd_others_hist = hist_template.Clone()
        others.draw_into(qcd_others_hist, expr, category, fit_region,
                cuts=control_region, systematics=False)

        qcd_hist = qcd_data_hist - qcd_tau_hist - qcd_others_hist

        # construct QCD shape systematic from OSFF model
        # OSFF x (SS / SSFF)
        qcd_osff_data_hist = hist_template.Clone()
        data.draw_into(qcd_osff_data_hist, expr, category, 'OSFF',
                cuts=control_region, systematics=False)

        qcd_osff_tau_hist = hist_template.Clone()
        ztt.draw_into(qcd_osff_tau_hist, expr, category, 'OSFF',
                cuts=control_region, systematics=False)

        qcd_osff_others_hist = hist_template.Clone()
        others.draw_into(qcd_osff_others_hist, expr, category, 'OSFF',
                cuts=control_region, systematics=False)

        qcd_ssff_data_hist = hist_template.Clone()
        data.draw_into(qcd_ssff_data_hist, expr, category, 'SSFF',
                cuts=control_region, systematics=False)

        qcd_ssff_tau_hist = hist_template.Clone()
        ztt.draw_into(qcd_ssff_tau_hist, expr, category, 'SSFF',
                cuts=control_region, systematics=False)

        qcd_ssff_others_hist = hist_template.Clone()
        others.draw_into(qcd_ssff_others_hist, expr, category, 'SSFF',
                cuts=control_region, systematics=False)

        qcd_syst = (qcd_osff_data_hist - qcd_osff_tau_hist - qcd_osff_others_hist) * (
                qcd_hist / (
                    qcd_ssff_data_hist - qcd_ssff_tau_hist - qcd_ssff_others_hist))

        fitter = ROOT.TrackFit.TrackFitter(1)
        fit_result = fitter.fit(
                data_hist, tau_hist, qcd_hist, others_hist,
                # qcd_syst, qcd_stat
                qcd_syst, qcd_hist,
                # tau PU low, tau PU high
                tau_hist, tau_hist)

        # Cache the fitted normalization scale factors for SS
        cache.set_scales(
            year,
            category.name,
            False,
            param,
            fit_region,
            qcd_scale=fit_result.sf_QCD,
            qcd_scale_error=fit_result.sf_QCD_err,
            qcd_data_scale=1.,
            qcd_z_scale=1.,
            qcd_others_scale=1.,
            z_scale=fit_result.sf_Z,
            z_scale_error=fit_result.sf_Z_err)

        cache.set_scales(
            year,
            category.name,
            True, # Embedded Z
            param,
            fit_region,
            qcd_scale=fit_result.sf_QCD,
            qcd_scale_error=fit_result.sf_QCD_err,
            qcd_data_scale=1.,
            qcd_z_scale=1.,
            qcd_others_scale=1.,
            z_scale=fit_result.sf_Z * sf_embed,
            z_scale_error=fit_result.sf_Z_err * sf_embed)

        qcd_scale = fit_result.sf13_QCD
        qcd_scale_error = fit_result.sf13_QCD_err

        z_scale = fit_result.sf13_Z * scale_init
        z_scale_error = fit_result.sf13_Z_err * scale_init

        """ Iterative approach
        # QCD = C x [A x Data - B x Z - O]

        A = 1.
        B = 1.
        C = 1.
        C_prev = 0
        C_error = None
        B_error = None

        iteration = 1
        # converge on the fitted values of A and B until C is close to 1.
        while abs(C - C_prev) > 0.01:

            qcd_hist = (qcd_data_hist * A - qcd_tau_hist * B - qcd_others_hist) * C
            tau_hist_float = tau_hist * B

            fit_result = fitter.fit(
                data_hist, tau_hist_float, qcd_hist, others_hist,
                # qcd_syst, qcd_stat
                qcd_syst, qcd_hist,
                # tau PU low, tau PU high
                tau_hist_float, tau_hist_float)

            C_prev = C
            C = fit_result.sf13_QCD
            B *= fit_result.sf13_Z

            if C_error is None:
                C_error = fit_result.sf13_QCD_err
                B_error = fit_result.sf13_Z_err
            else:
                C_error *= fit_result.sf13_QCD
                B_error *= fit_result.sf13_Z

            log.info("TrackFit iteration %d" % iteration)
            log.info("sf_QCD: %.4f +/- %.4f sf_Z: %.4f +/- %.4f" % (C, C_error, B, B_error))
            iteration += 1
            break

        qcd_scale = C
        qcd_scale_error = C_error

        z_scale = B * scale_init
        z_scale_error = B_error * scale_init
        """

        qcd.scale = qcd_scale
        qcd.scale_error = qcd_scale_error
        ztt.scale = z_scale
        ztt.scale_error = z_scale_error

        if args.plot:
            # Draw the distribution after the fit
            draw_samples(hist_template, expr,
                model=[qcd, others, ztt],
                data=data,
                category=category,
                region=model_region,
                cuts=control_region,
                name=xaxis_label,
                output_name=after_name,
                show_ratio=True,
                systematics=None,
                ravel=hist_template.GetDimension() > 1,
                integer=integer,
                xtick_formatter=xtick_formatter,
                xtick_rotation=xtick_rotation,
                output_formats=['eps', 'png'])

        """
        # correct to f13QCD
        f13_current = qcd.events(category, 'SS', cuts=P1P3_RECOUNTED & control_region) / qcd.events(category, 'SS', cuts=control_region)
        qcd_scale_correct = fit_result.f13_QCD / f13_current

        qcd_scale *= qcd_scale_correct
        qcd_scale_error *= qcd_scale_correct

        qcd.scale = qcd_scale
        qcd.scale_error = qcd_scale_error

        nZ = (data.events(category, 'OS_TRK', cuts=control_region)
                - others.events(category, 'OS_TRK', cuts=control_region)
                - qcd.events(category, 'SS', cuts=P1P3_RECOUNTED & control_region))

        z_scale_correct = nZ / ztt.events(category, 'OS_TRK', cuts=control_region)

        z_scale *= z_scale_correct
        z_scale_error *= z_scale_correct

        ztt.scale = z_scale
        ztt.scale_error = z_scale_error
        """

        # Cache the fitted normalization scale factors for SS_TRK
        cache.set_scales(
            year,
            category.name,
            False,
            param,
            fit_region_alias,
            qcd_scale=qcd_scale,
            qcd_scale_error=qcd_scale_error,
            qcd_data_scale=1.,
            qcd_z_scale=1.,
            qcd_others_scale=1.,
            z_scale=z_scale,
            z_scale_error=z_scale_error)

        cache.set_scales(
            year,
            category.name,
            True, # Embedded Z
            param,
            fit_region_alias,
            qcd_scale=qcd_scale,
            qcd_scale_error=qcd_scale_error,
            qcd_data_scale=1.,
            qcd_z_scale=1.,
            qcd_others_scale=1.,
            z_scale=z_scale * sf_embed_13,
            z_scale_error=z_scale_error * sf_embed_13)

        """
                     nOS QCD Model
        ==========================================

                        |Data(SS_TRK)|
        QCD(nOS) =  A x -------------- x Data(nOS)
                         |Data(nOS)|

                          |Z(SS_TRK)|
                    - B x ----------- x Z(nOS)
                           |Z(nOS)|

                      |Others(SS_TRK)|
                    - ---------------- x Others(nOS)
                       |Others(nOS)|


        -  OR  -


                   |QCD(SS_TRK)|
        QCD(nOS) = ------------- x (Data(nOS) - Z(nOS) - Others(nOS))
                    |QCD(nOS)|

        Correct the QCD scale to account for difference between fitting model
        and target model (SS vs !OS). The final OS model includes the
        requirement that the number of recounted tracks equals 1 or 3
        for both taus, so we need to scale the QCD to what would be expected
        after this requirement

        Note: All regions are defined in mva/regions.py
        """

        """
        # correct each term separately
        sf_data   = (data.events(category, 'SS_TRK') /
                     float(data.events(category, 'nOS')))

        sf_ztt    = (ztt.events(category, 'SS_TRK') /
                     float(ztt.events(category, 'nOS')))

        sf_others = (others.events(category, 'SS_TRK') /
                     float(others.events(category, 'nOS')))

        qcd_data_scale_nos = qcd_data_scale * sf_data
        qcd_z_scale_nos = sf_ztt
        qcd_others_scale_nos = sf_others
        """

        qcd_data_scale_nos = 1.
        qcd_z_scale_nos = 1.
        qcd_others_scale_nos = 1.

        qcd.shape_region = 'SS_TRK'
        qcd_events_ss = qcd.events(category, 'SS_TRK')[1].value
        qcd.shape_region = 'nOS'
        qcd_events_nos = qcd.events(category, 'nOS')[1].value

        sf_qcd = qcd_events_ss / float(qcd_events_nos)

        qcd_scale_nos = qcd_scale * sf_qcd
        qcd_scale_error_nos = qcd_scale_error * sf_qcd

        cache.set_scales(
            year,
            category.name,
            False,
            param,
            'nOS',
            qcd_scale=qcd_scale_nos,
            qcd_scale_error=qcd_scale_error_nos,
            qcd_data_scale=qcd_data_scale_nos,
            qcd_z_scale=qcd_z_scale_nos,
            qcd_others_scale=qcd_others_scale_nos,
            z_scale=z_scale,
            z_scale_error=z_scale_error)

        cache.set_scales(
            year,
            category.name,
            True, # embedded Z
            param,
            'nOS',
            qcd_scale=qcd_scale_nos,
            qcd_scale_error=qcd_scale_error_nos,
            qcd_data_scale=qcd_data_scale_nos,
            qcd_z_scale=qcd_z_scale_nos,
            qcd_others_scale=qcd_others_scale_nos,
            z_scale=z_scale * sf_embed_13,
            z_scale_error=z_scale_error * sf_embed_13)
